{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3svl6bpwMfxP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxzFv2M7bQUv",
        "outputId": "57256b8d-7385-414a-eb23-50b352877388"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.32.0\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wfHduUUCbRAV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ByqGWZ2bVv6",
        "outputId": "3392328a-1a2b-4cf9-d049-54a66e4fd3ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YFHKU7mDbbM_"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 100\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "no_of_classes_sentiment = 3\n",
        "no_of_classes_topic = 8\n",
        "\n",
        "PRE_TRAINED_MODEL_NAME = '/content/drive/MyDrive/fmc/huggingface_bert_model.bin'\n",
        "tokenizer = BertTokenizer.from_pretrained(\"/content/drive/MyDrive/fmc/tsel_cx_tnps_sentiment_token.bin\")\n",
        "\n",
        "FINE_TUNED_MODEL_NAME_SENTIMENT = ''\n",
        "FINE_TUNED_MODEL_NAME_TOPIC = ''\n",
        "\n",
        "class_params_senti = {}\n",
        "class_params_topic = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "T2VeSPKUb0Co"
      },
      "outputs": [],
      "source": [
        "class TselDataset(Dataset):\n",
        "\n",
        "  def __init__(self, texts, targets, tokenizer, max_len):\n",
        "    self.texts = texts\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.texts[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      #pad_to_max_length=True,\n",
        "      padding='max_length',\n",
        "      truncation=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }\n",
        "\n",
        "\n",
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = TselDataset(\n",
        "    texts=df.text.to_numpy(),\n",
        "    targets=df.label.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=2\n",
        "  )\n",
        "\n",
        "class TextClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(TextClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.2)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output[1])\n",
        "    return self.out(output)\n",
        "\n",
        "\n",
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHHCCKG8cBr1",
        "outputId": "664647a6-a8bd-48ba-8be7-7484a134c97e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_topic = TextClassifier(no_of_classes_topic)\n",
        "model_topic = model_topic.to(device)\n",
        "state_dict_topic = torch.load(FINE_TUNED_MODEL_NAME_TOPIC, map_location=device)\n",
        "model_topic.load_state_dict(state_dict_topic)\n",
        "\n",
        "model_sentiment = TextClassifier(no_of_classes_sentiment)\n",
        "model_sentiment = model_sentiment.to(device)\n",
        "state_dict_sentiment = torch.load(FINE_TUNED_MODEL_NAME_SENTIMENT, map_location=device)\n",
        "model_sentiment.load_state_dict(state_dict_sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_dataframe_names = ['tnps_datamart_part-0.csv', 'tnps_datamart_part-1.csv', 'tnps_datamart_part-2.csv', 'tnps_datamart_part-3.csv', 'tnps_datamart_part-4.csv', 'tnps_datamart_part-5.csv']\n",
        "\n",
        "output_dataframe_names = ['output_tnps_datamart_part-0.csv', 'output_tnps_datamart_part-1.csv', 'output_tnps_datamart_part-2.csv', 'output_tnps_datamart_part-3.csv', 'output_tnps_datamart_part-4.csv', 'output_tnps_datamart_part-5.csv']\n",
        "\n",
        "def pairing_function(self, x, y):\n",
        "    mydic = {}\n",
        "    for i in zip(dict(sorted(y.items(), key=lambda x:x[1])), x):\n",
        "        mydic[i[0]] = i[1]\n",
        "\n",
        "    return mydic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, csv_name in enumerate(input_dataframe_names):\n",
        "    df = pd.read_csv(csv_name)\n",
        "    dfp = pd.DataFrame({\n",
        "        'text': df['sentiment_text'],\n",
        "        'label': [0]*df.shape[0]\n",
        "    })\n",
        "\n",
        "    # PRE-PROCESS\n",
        "    dfp['text'] = dfp['text'].replace('\\d+|[^\\w\\s]|NULL|~', ' ', regex=True)\n",
        "    dfp['text'] = dfp['text'].str.strip()\n",
        "\n",
        "    dfp_final = dfp[(dfp['text'] != '') & (dfp['text'].notnull())]\n",
        "\n",
        "    predicting_data_loader = create_data_loader(dfp_final, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "\n",
        "    # MAIN-PROCESS\n",
        "    # Topic\n",
        "    y_review_texts_topic, y_pred_topic, y_pred_probs_topic, y_test_topic = get_predictions(\n",
        "        model_topic,\n",
        "        predicting_data_loader\n",
        "    )\n",
        "\n",
        "    # Sentiment\n",
        "    y_review_texts_sent, y_pred_sent, y_pred_probs_sent, y_test_sent = get_predictions(\n",
        "        model_sentiment,\n",
        "        predicting_data_loader\n",
        "    )\n",
        "\n",
        "    # POST-PROCESS\n",
        "    y_prediction_probs_topic_df = pd.DataFrame({\n",
        "        'y_pred_proba': y_pred_probs_topic.tolist()\n",
        "    })\n",
        "\n",
        "    y_prediction_probs_senti_df = pd.DataFrame({\n",
        "        'y_pred_proba': y_pred_probs_sent.tolist()\n",
        "    })\n",
        "\n",
        "    y_prediction_probs_topic = np.vectorize(pairing_function)(\n",
        "        y_prediction_probs_topic_df['y_pred_proba'], class_params_topic)\n",
        "\n",
        "    y_prediction_probs_sentiment = np.vectorize(pairing_function)(\n",
        "        y_prediction_probs_senti_df['y_pred_proba'], class_params_senti)\n",
        "\n",
        "    # Post-process (assign to raw dataframe)\n",
        "    dfp_final['y_pred_topic'] = y_pred_topic\n",
        "    dfp_final['y_pred_proba_topic'] = y_prediction_probs_topic\n",
        "    dfp_final['y_pred_sentiment'] = y_pred_sent\n",
        "    dfp_final['y_pred_proba_sentiment'] = y_prediction_probs_sentiment\n",
        "\n",
        "    # Joining data\n",
        "    df_new = df.merge(dfp_final.iloc[:,2:], left_index=True, right_index=True, how='outer')\n",
        "    \n",
        "    df_new.to_csv(output_dataframe_names[i], index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
