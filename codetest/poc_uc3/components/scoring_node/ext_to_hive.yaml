name: ext to hive
description: store scoring result as external hive table
inputs:
- {name: dataSource, type: String,  optional: false, description: 'Data source (ex. TNPS, KIP, App-Review, Social-Media)'}
- {name: filePath, type: String,  optional: false, description: 'Parquet file to be read'}
- {name: databaseName, type: String,  optional: false, description: 'Database to be stored'}
- {name: tableName, type: String,  optional: false, description: 'Table name to be stored'}
- {name: writeMode, type: String,  optional: false, description: 'Write mode (append/overwrite)'}

implementation:
  container:
    image: docker.cicd-jfrog.telkomsel.co.id/kubeflow-mlops-dev/cloudera-base-cdp:centos7-cdp-v1.0.0
    env:
      #Working Directory Information
      "WORKING_DIR": "ext_to_hive"
      
      #Notebook Information
      "USER_NAME": "@mlcore_user_name@"
      "GROUP_NAME": "@mlcore_group_name@"
      "PROJECT_NAME": "@mlcore_project_name@"

      #Gitlab Access
      "MLCORE_GIT_ROOTURL" : "@mlcore_gitlab_rooturl@"
      "REPO_NAME": "@mlcore_repo_name@"
      "BRANCH": "@mlcore_branch_name@"
      "DEST_LOCATION" : "./"
      "MLCORE_GITLAB_TOKEN": "@mlcore_gitlab_cx_token@"
      "MLCORE_GITLAB_USER": "@mlcore_gitlab_cx_user@"
      "MLCORE_GITLAB_PASSWORD": "@mlcore_gitlab_cx_password@"
      "MLCORE_USER_NAME": "@mlcore_email_user@" #Input your information

      #Kerberos Authentication
      "LDAP_USERNAME" : "@mlcore_ldap_username@" #Input your information
      "LDAP_PASSWORD" : "@mlcore_ldap_password@" #Input your information

      #Spark Queue
      "SPARK_QUEUE" : "root.s_mkt.hui_xc_ops"  #Input your information
    command: 
      - sh
      - -ec
      - |
        python3 /home/jovyan/git_clone.py && 
        pip install -r $REPO_NAME/nodes/scoring_node/$WORKING_DIR/requirements.txt && 
        echo "$LDAP_PASSWORD" | kinit $LDAP_USERNAME && 
        spark-submit --queue $SPARK_QUEUE --driver-memory 16g --master yarn  $REPO_NAME/nodes/scoring_node/$WORKING_DIR/main.py --data-source "$@" --file-path "$@" --database-name "$@" --table-name "$@" --write-mode "$@" --repo-name $REPO_NAME
    args:
    - --data-source
    - {inputValue: dataSource}
    - --file-path
    - {inputPath: filePath}
    - --database-name
    - {inputValue: databaseName}
    - --table-name
    - {inputValue: tableName}
    - --write-mode
    - {inputValue: writeMode}
