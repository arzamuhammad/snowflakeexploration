{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b5a7a5-d7c0-4d65-bd73-2348fd9e0d43",
   "metadata": {
    "id": "_KfvgQy3yi7H"
   },
   "source": [
    "# **Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe9e7cf4-0346-4f14-bea5-7de36c604d1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vPrJJgGOdgH9",
    "outputId": "a95b1421-a7e2-4877-d0cf-40c78adb47b9"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import pyproj\n",
    "import shapely\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84bac057-d76d-49a2-ac2e-47f65f81a85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n",
      "1.5.3\n",
      "3.7.0\n",
      "2.0.6\n",
      "1.5.2\n"
     ]
    }
   ],
   "source": [
    "print(numpy.__version__)\n",
    "print(pandas.__version__)\n",
    "print(pyproj.__version__)\n",
    "print(shapely.__version__)\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52dfc3f4-c668-4118-bf6b-8db26774cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import h3\n",
    "import h3_pyspark\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lag, lead\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, IntegerType, TimestampType, StringType, DateType\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09f2e882-8263-4a60-a668-1c74919835e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas :  1.5.3\n",
      "geopandas :  1.0.1\n",
      "pyspark :  3.3.4\n",
      "sedona :  1.2.1\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "from functools import reduce\n",
    "from math import asin, atan2, cos, degrees, floor, radians, sin, sqrt\n",
    "\n",
    "import geopandas as gpd\n",
    "import geopy\n",
    "import h3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import sedona\n",
    "# import rasterio\n",
    "from pyspark import SparkContext\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from shapely.wkt import loads\n",
    "\n",
    "print(\"pandas : \", pd.__version__)\n",
    "print(\"geopandas : \", gpd.__version__)\n",
    "print(\"pyspark : \", pyspark.__version__)\n",
    "print(\"sedona : \", sedona.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab9333d4-9b94-4ad0-b3ee-99380d7fc112",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYSPARK_PYTHON\"] = \"./env/bin/python\"\n",
    "os.environ[\"HADOOP_CONF_DIR\"] = \"/etc/spark3/conf.cloudera.spark3_on_yarn/yarn-conf\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"/opt/cloudera/parcels/CDH/lib/hadoop\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/cloudera/parcels/SPARK3-3.3.2.3.3.7190.4-1-1.p0.51021169/lib/spark3\"\n",
    "os.environ[\"SPARK_CONF_DIR\"] = \"/etc/spark3/conf.cloudera.spark3_on_yarn\"\n",
    "\n",
    "conf = (\n",
    "    SparkConf()\n",
    "    .setMaster(\"yarn\")\n",
    "    .setAppName(\"data-cerdas-rerun\")\n",
    "    .set(\"spark.dynamicAllocation.maxExecutors\", \"50\")\n",
    "    .set(\"spark.dynamicAllocation.minExecutors\", \"1\")\n",
    "    .set(\"spark.executor.cores\", \"12\")\n",
    "    .set(\"spark.executor.memory\", \"64g\")\n",
    "    .set(\"spark.sql.shuffle.partitions\", \"7000\")\n",
    "    .set(\"spark.yarn.queue\", \"root.pnt.hui_pnt_bpsint\")\n",
    "    .set(\"spark.driver.maxResultSize\",\"8g\")\n",
    "    .set(\n",
    "        \"spark.yarn.appMasterEnv.PYSPARK_PYTHON\",\n",
    "        \"./env/bin/python\",\n",
    "    )\n",
    "    .set(\n",
    "        \"spark.yarn.dist.archives\", \"hdfs://nsdiscovery/warehouse/tablespace/external/hive/pnt_bps_int.db/envs/mobility_310.tar.gz#env\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aee6fbc4-7da0-4873-b82e-922c91356867",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/24 11:35:31 WARN  util.Utils: [Thread-3]: Service 'sparkDriver' could not bind on port 30060. Attempting port 30061.\n",
      "25/03/24 11:35:31 WARN  util.Utils: [Thread-3]: Service 'sparkDriver' could not bind on port 30061. Attempting port 30062.\n",
      "25/03/24 11:35:32 WARN  util.Utils: [Thread-3]: Service 'SparkUI' could not bind on port 30072. Attempting port 30073.\n",
      "25/03/24 11:35:32 WARN  util.Utils: [Thread-3]: Service 'SparkUI' could not bind on port 30073. Attempting port 30074.\n",
      "25/03/24 11:35:35 WARN  conf.HiveConf: [Thread-3]: HiveConf of name hive.metastore.runworker.in does not exist\n",
      "25/03/24 11:35:35 WARN  conf.HiveConf: [Thread-3]: HiveConf of name hive.masking.algo does not exist\n",
      "25/03/24 11:35:37 WARN  util.Utils: [Thread-3]: spark.executor.instances less than spark.dynamicAllocation.minExecutors is invalid, ignoring its setting, please update your configs.\n",
      "25/03/24 11:35:38 WARN  ipc.Client: [Thread-3]: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error\n",
      "25/03/24 11:35:40 WARN  ipc.Client: [Thread-3]: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error\n",
      "25/03/24 11:35:56 WARN  util.Utils: [Thread-3]: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 30066. Attempting port 30067.\n",
      "25/03/24 11:35:56 WARN  util.Utils: [Thread-3]: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 30067. Attempting port 30068.\n",
      "25/03/24 11:35:56 WARN  util.Utils: [Thread-3]: spark.executor.instances less than spark.dynamicAllocation.minExecutors is invalid, ignoring its setting, please update your configs.\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d74579b-c4e6-437c-96cf-0e92768e31d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.53.176.16:30074\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2.3.3.7190.4-1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>data-cerdas-rerun</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb1ec61d930>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac01a082-f644-446c-8e0c-81b887618dce",
   "metadata": {},
   "source": [
    "# UE Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19403f05-9a49-4ae1-9d5b-5e98b264785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prep_lbs(lbs,filter_month):\n",
    "    lbs = lbs.filter(F.substring('calling_date',1,7)==filter_month)\n",
    "    lbs = lbs\\\n",
    "            .withColumnRenamed('hash_msisdn', 'imsi')\\\n",
    "            .withColumnRenamed('encrypted_msisdn', 'imsi')\\\n",
    "            .withColumn('msisdn', f.col('imsi').cast(StringType()))\n",
    "    \n",
    "    lbs = lbs.withColumn('h3_10', latlon_h3(F.col('latitude').cast('double'),F.col('longitude').cast('double') , f.lit(10)))\n",
    "    return lbs\n",
    "\n",
    "def join_lbs_lau(lbs,lau):\n",
    "    lbs = lbs.join(lau, ['h3_10'], 'left')\n",
    "    lbs = lbs.withColumn('h3_8', h3_parent('h3_10', f.lit(8)))\n",
    "    lbs = lbs.repartition('msisdn')\n",
    "    return lbs\n",
    "\n",
    "def haversine_distance(lon1, lat1, lon2, lat2):\n",
    "    R = 6371.0  # Earth's radius in kilometers\n",
    "    dlat = f.radians(lat2 - lat1)\n",
    "    dlon = f.radians(lon2 - lon1)\n",
    "    a = f.pow(f.sin(dlat/2), 2) + \\\n",
    "        f.cos(f.radians(lat1)) * f.cos(f.radians(lat2)) * f.pow(f.sin(dlon/2), 2)\n",
    "    c = 2 * f.atan2(f.sqrt(a), f.sqrt(1-a))\n",
    "    return f.round(R * c, 2)\n",
    "\n",
    "def process_ue_monthly(lbs):\n",
    "    part = Window.partitionBy('msisdn').orderBy(['datetime'])\n",
    "    \n",
    "    home_start  = 0\n",
    "    home_end    = 5\n",
    "    work_start  = 8\n",
    "    work_end    = 16\n",
    "    home_start2 = 20\n",
    "    home_end2   = 23\n",
    "\n",
    "    lbs_weekday_stop = lbs\\\n",
    "                        .withColumn('latitude', f.round(f.col('latitude').cast('double'), 5)) \\\n",
    "                        .withColumn('longitude', f.round(f.col('longitude').cast('double'), 5)) \\\n",
    "                        .dropDuplicates(['msisdn','datetime','longitude','latitude'])\\\n",
    "                        .withColumn('event_day', f.date_format(col('datetime'), 'E'))\\\n",
    "                        .withColumn('day_type', f.when((col('event_day')=='Sat') | (col('event_day')=='Sun'),'weekend').otherwise('weekday') )\\\n",
    "                        .filter(col('day_type') == 'weekday')\\\n",
    "                        .withColumn('prev_latitude', f.lag('latitude').over(part))\\\n",
    "                        .withColumn('prev_longitude', f.lag('longitude').over(part))\\\n",
    "                        .withColumn('prev_datetime', f.lag('datetime').over(part))\\\n",
    "                        .withColumn('time_seconds', f.unix_timestamp('datetime') - f.unix_timestamp('prev_datetime')) \\\n",
    "                        .withColumn('distance',  haversine_distance(col('prev_longitude'), col('prev_latitude'), col('longitude'), col('latitude')) )\\\n",
    "                        .withColumn('speed', f.round( col('distance') / (col('time_seconds') / 3600) ,2) )\\\n",
    "                        .filter(col('speed') <= 10.0)\\\n",
    "                        .withColumn('month', f.format_string(\"%04d-M%02d\", f.year(col('datetime')), f.month(col('datetime'))) )\\\n",
    "                        .withColumn('date', f.to_date(col('datetime')) )\\\n",
    "                        .withColumn('hour', f.hour(col('datetime')) )\\\n",
    "                        .withColumn('hour_category', f.when( (col('hour') >= home_start) & (col('hour') <= home_end), 'home' )\\\n",
    "                                                      .when( (col('hour') >= work_start) & (col('hour') <= work_end), 'work' )\\\n",
    "                                                      .when( (col('hour') >= home_start2) & (col('hour') <= home_end2), 'home' )\\\n",
    "                                                      .otherwise('others') )\\\n",
    "                        .withColumn('activity_kab', f.col('kab'))\\\n",
    "                        .withColumn('activity_kec', f.col('kec'))\n",
    "    \n",
    "    part2 = Window.partitionBy(['msisdn', 'month', 'h3_8', 'activity_kec', 'hour_category'])\n",
    "\n",
    "    part3 = Window.partitionBy(['msisdn', 'month', 'hour_category'])\\\n",
    "                  .orderBy([col('total_date').desc(), col('total_count').desc(), 'entropy'])\n",
    "    \n",
    "    ue = lbs_weekday_stop \\\n",
    "          .groupBy('msisdn', 'month', 'h3_8', 'activity_kec', 'hour_category', 'hour')\\\n",
    "          .agg(\n",
    "                f.count('*').alias('N'),\n",
    "                f.countDistinct('date').alias('N_date'),\n",
    "              )\\\n",
    "          .filter(col('N_date') >= 5 )\\\n",
    "          .withColumn('total_date', f.sum('N_date').over(part2)) \\\n",
    "          .withColumn('total_count', f.sum('N').over(part2)) \\\n",
    "          .withColumn('prob', f.col('N') / f.col('total_count')) \\\n",
    "          .withColumn('entropy', f.round(-f.sum(f.col('prob') * f.log2(f.col('prob'))).over(part2),2) ) \\\n",
    "          .withColumn('rank', f.dense_rank().over(part3) )\\\n",
    "          .filter( (col('rank') == 1) & ~(col('hour_category') == 'others') )\\\n",
    "          .select(['msisdn', 'month', 'h3_8', 'activity_kec', 'entropy', 'hour_category'])\\\n",
    "          .distinct()\n",
    "    \n",
    "    ue_monthly = ue\\\n",
    "                  .groupBy('msisdn', 'month')\\\n",
    "                  .agg(\n",
    "                        f.min(f.when(col('hour_category')=='home',col('h3_8'))).alias('home_h3_8'),\n",
    "                        f.min(f.when(col('hour_category')=='home',col('activity_kec'))).alias('home_kec'),\n",
    "                        f.min(f.when(col('hour_category')=='home',col('entropy'))).alias('home_entropy'),\n",
    "                        f.min(f.when(col('hour_category')=='work',col('h3_8'))).alias('work_h3_8'),\n",
    "                        f.min(f.when(col('hour_category')=='work',col('activity_kec'))).alias('work_kec'),\n",
    "                        f.min(f.when(col('hour_category')=='work',col('entropy'))).alias('work_entropy')\n",
    "                  )\\\n",
    "                  .withColumn('home_kab', col('home_kec').substr(0, 5))\\\n",
    "                  .withColumn('work_kab', col('work_kec').substr(0, 5))\\\n",
    "                  .withColumn('date', f.to_date(f.concat_ws('-', col('month').substr(0, 4), col('month').substr(7, 2), f.lit('01')), 'yyyy-MM-dd') )\\\n",
    "                  .withColumn('date_6m_ago', f.add_months(col('date'), -5) )\\\n",
    "                  .withColumn('date', f.last_day(col('date')) )\\\n",
    "    \n",
    "    return ue_monthly\n",
    "\n",
    "def process_data(\n",
    "    lbs,\n",
    "    lau,\n",
    "    filter_month\n",
    "):\n",
    "        \n",
    "    lbs = prep_lbs(lbs,filter_month)\n",
    "    lbs = join_lbs_lau(lbs,lau)\n",
    "    ue_monthly = process_ue_monthly(lbs)\n",
    "    return ue_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db8c454f-5250-4458-abd5-fa9e4e039682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/24 11:36:04 WARN  conf.HiveConf: [Thread-3]: HiveConf of name hive.metastore.runworker.in does not exist\n",
      "25/03/24 11:36:04 WARN  conf.HiveConf: [Thread-3]: HiveConf of name hive.masking.algo does not exist\n",
      "25/03/24 11:36:04 WARN  client.HiveClientImpl: [Thread-3]: Detected HiveConf hive.execution.engine is 'tez' and will be reset to 'mr' to disable useless hive logic\n",
      "Hive Session ID = 4fd37de9-9598-48e8-8ead-70933b64574e\n",
      "25/03/24 11:36:05 WARN  conf.HiveConf: [Thread-3]: HiveConf of name hive.metastore.runworker.in does not exist\n",
      "25/03/24 11:36:05 WARN  conf.HiveConf: [Thread-3]: HiveConf of name hive.masking.algo does not exist\n"
     ]
    }
   ],
   "source": [
    "h3_parent = f.udf(lambda h3_str,size:h3.cell_to_parent(h3_str,size) if h3_str else None, returnType=StringType())\n",
    "latlon_h3 = F.udf(lambda lat,lon,size:h3.latlng_to_cell(lat,lon,size) if lat != None and lon != None else None)\n",
    "\n",
    "lau = spark.read.table('pe_bps.indonesia_h3_38prov')\n",
    "# lbs = spark.read.table('p_gsa_stg.lbs_genome')\n",
    "lbs = spark.read.table('pe_bps.wisnus_sample5_lbs_2024')\n",
    "\n",
    "filter_month = '2024-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93d65214-50d7-4b1f-a3ff-8861e52e2b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "ue_monthly = process_data(\n",
    "    lbs,\n",
    "    lau,\n",
    "    filter_month\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763845f9-e3fe-4b16-9a29-7db78e49e955",
   "metadata": {},
   "source": [
    "## Looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61025270-127b-48e1-afa8-c0f720b76a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configure the logging to save to a file\n",
    "logging.basicConfig(\n",
    "    filename='logs/logging_ue_monthly_sample.log',  # Name of the log file\n",
    "    level=logging.INFO,  # Set the logging level to INFO\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # Define the format of log messages\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'  # Date format\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0360633-5f2d-4446-81ba-6f7b2aba0b54",
   "metadata": {},
   "source": [
    "## Atur Bulan Di sini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c2fd05-6af6-4eaa-a3d2-a8e89d0b4bcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/24 11:36:13 WARN  metastore.RetryingMetaStoreClient: [Thread-3]: MetaStoreClient lost connection. Attempting to reconnect (1 of 1) after 1s. listPartitionsWithAuthInfo\n",
      "org.apache.thrift.transport.TTransportException: SASL authentication not complete\n",
      "\tat org.apache.thrift.transport.TSaslTransport.write(TSaslTransport.java:442) ~[libthrift-0.16.0.jar:0.16.0]\n",
      "\tat org.apache.thrift.transport.TSaslClientTransport.write(TSaslClientTransport.java:39) ~[libthrift-0.16.0.jar:0.16.0]\n",
      "\tat org.apache.hadoop.hive.metastore.security.TFilterTransport.write(TFilterTransport.java:73) ~[hive-standalone-metastore-3.1.3000.7.1.9.4-4.jar:3.1.3000.7.1.9.4-4]\n",
      "\tat org.apache.thrift.protocol.TBinaryProtocol.writeI32(TBinaryProtocol.java:204) ~[libthrift-0.16.0.jar:0.16.0]\n",
      "\tat org.apache.thrift.protocol.TBinaryProtocol.writeMessageBegin(TBinaryProtocol.java:119) ~[libthrift-0.16.0.jar:0.16.0]\n",
      "\tat org.apache.thrift.TServiceClient.sendBase(TServiceClient.java:70) ~[libthrift-0.16.0.jar:0.16.0]\n",
      "\tat org.apache.thrift.TServiceClient.sendBase(TServiceClient.java:62) ~[libthrift-0.16.0.jar:0.16.0]\n",
      "\tat org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.send_get_partitions_ps_with_auth_req(ThriftHiveMetastore.java:3685) ~[hive-standalone-metastore-3.1.3000.7.1.9.4-4.jar:3.1.3000.7.1.9.4-4]\n",
      "\tat org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_partitions_ps_with_auth_req(ThriftHiveMetastore.java:3677) ~[hive-standalone-metastore-3.1.3000.7.1.9.4-4.jar:3.1.3000.7.1.9.4-4]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.listPartitionsWithAuthInfoInternal(HiveMetaStoreClient.java:1966) ~[hive-standalone-metastore-3.1.3000.7.1.9.4-4.jar:3.1.3000.7.1.9.4-4]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.listPartitionsWithAuthInfo(HiveMetaStoreClient.java:1938) ~[hive-standalone-metastore-3.1.3000.7.1.9.4-4.jar:3.1.3000.7.1.9.4-4]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.listPartitionsWithAuthInfo(SessionHiveMetaStoreClient.java:1077) ~[hive-exec-3.1.3000.7.1.9.4-4-core.jar:3.1.3000.7.1.9.4-4]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.listPartitionsWithAuthInfo(HiveMetaStoreClient.java:1926) ~[hive-standalone-metastore-3.1.3000.7.1.9.4-4.jar:3.1.3000.7.1.9.4-4]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:566) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:213) ~[hive-standalone-metastore-3.1.3000.7.1.9.4-4.jar:3.1.3000.7.1.9.4-4]\n",
      "\tat com.sun.proxy.$Proxy55.listPartitionsWithAuthInfo(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:566) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient$SynchronizedHandler.invoke(HiveMetaStoreClient.java:3759) ~[hive-standalone-metastore-3.1.3000.7.1.9.4-4.jar:3.1.3000.7.1.9.4-4]\n",
      "\tat com.sun.proxy.$Proxy55.listPartitionsWithAuthInfo(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getPartitions(Hive.java:3898) ~[hive-exec-3.1.3000.7.1.9.4-4-core.jar:3.1.3000.7.1.9.4-4]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getPartitions(Hive.java:3924) ~[hive-exec-3.1.3000.7.1.9.4-4-core.jar:3.1.3000.7.1.9.4-4]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.getPartitions(HiveShim.scala:682) ~[spark-hive_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$getPartitions$3(HiveClientImpl.scala:826) ~[spark-hive_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:324) ~[spark-hive_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:251) ~[spark-hive_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:250) ~[spark-hive_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:304) ~[spark-hive_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.getPartitions(HiveClientImpl.scala:819) ~[spark-hive_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.getPartitions(HiveClientImpl.scala:814) ~[spark-hive_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$listPartitions$1(HiveExternalCatalog.scala:1279) ~[spark-hive_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:101) ~[spark-hive_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.listPartitions(HiveExternalCatalog.scala:1276) ~[spark-hive_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.listPartitions(ExternalCatalogWithListener.scala:254) ~[spark-catalyst_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.listPartitions(SessionCatalog.scala:1263) ~[spark-catalyst_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:101) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.writeAndRead(DataSource.scala:538) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.execution.command.CreateDataSourceTableAsSelectCommand.saveDataIntoTable(createDataSourceTables.scala:228) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.execution.command.CreateDataSourceTableAsSelectCommand.run(createDataSourceTables.scala:169) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:99) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:99) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584) ~[spark-catalyst_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176) ~[spark-catalyst_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584) ~[spark-catalyst_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30) ~[spark-catalyst_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30) ~[spark-catalyst_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30) ~[spark-catalyst_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:560) ~[spark-catalyst_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:117) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.DataFrameWriter.createTable(DataFrameWriter.scala:710) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:688) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:574) ~[spark-sql_2.12-3.3.2.3.3.7190.4-1.jar:3.3.2.3.3.7190.4-1]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:566) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) ~[py4j-0.10.9.5.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357) ~[py4j-0.10.9.5.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) ~[py4j-0.10.9.5.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) ~[py4j-0.10.9.5.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) ~[py4j-0.10.9.5.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) ~[py4j-0.10.9.5.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) ~[py4j-0.10.9.5.jar:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) ~[?:?]\n",
      "25/03/24 11:41:04 WARN  conf.HiveConf: [SparkExecutionPlanProcessor-thread]: HiveConf of name hive.metastore.runworker.in does not exist\n",
      "25/03/24 11:41:04 WARN  conf.HiveConf: [SparkExecutionPlanProcessor-thread]: HiveConf of name hive.masking.algo does not exist\n",
      "25/03/24 11:41:04 WARN  util.package: [SparkExecutionPlanProcessor-thread]: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/03/24 11:41:05 WARN  producer.ProducerConfig: [Atlas Notifier 0]: These configurations '[key.deserializer, value.deserializer, max.poll.records, zookeeper.connection.timeout.ms, zookeeper.session.timeout.ms, enable.auto.commit, zookeeper.connect, zookeeper.sync.time.ms, session.timeout.ms, auto.offset.reset]' were supplied but are not used yet.\n",
      "25/03/24 11:48:43 WARN  hdfs.DataStreamer: [DataStreamer for file /user/spark/driver3Logs/application_1734575218783_2986275_driver.log]: Abandoning BP-925611003-10.53.176.2-1658822296038:blk_2601584904_1542216385\n",
      "25/03/24 11:48:43 WARN  hdfs.DataStreamer: [DataStreamer for file /user/spark/driver3Logs/application_1734575218783_2986275_driver.log]: Excluding datanode DatanodeInfoWithStorage[10.53.176.70:9866,DS-2e2beaf7-ff3c-4dc7-8581-187a9d897e2f,DISK]\n",
      "25/03/24 11:49:26 WARN  datasources.SharedInMemoryCache: [Thread-3]: Evicting cached table partition metadata from memory due to size constraints (spark.sql.hive.filesourcePartitionFileCacheSize = 262144000 bytes). This may impact query planning performance.\n",
      "25/03/24 12:00:19 WARN  hdfs.DataStreamer: [DataStreamer for file /user/spark/driver3Logs/application_1734575218783_2986275_driver.log]: Abandoning BP-925611003-10.53.176.2-1658822296038:blk_2601632219_1542263983\n",
      "25/03/24 12:00:19 WARN  hdfs.DataStreamer: [DataStreamer for file /user/spark/driver3Logs/application_1734575218783_2986275_driver.log]: Excluding datanode DatanodeInfoWithStorage[10.53.176.172:9866,DS-bc0ec0a6-404b-4ef8-a30e-54076f3d43e4,DISK]\n",
      "[Stage 84:========> (1596 + 398) / 1994][Stage 85:===>      (1919 + 178) / 4864]"
     ]
    }
   ],
   "source": [
    "list_date = pd.date_range('2024-04','2024-11',freq='MS')\n",
    "for datetime in list_date:\n",
    "    \n",
    "    filter_month = datetime.strftime('%Y-%m')\n",
    "    logging.info(f'PROCESS: {filter_month}')\n",
    "    ue_monthly = process_data(\n",
    "        lbs,\n",
    "        lau,\n",
    "        filter_month\n",
    "    )\n",
    "    ue_monthly.repartition(100).write.partitionBy('month').mode('append').saveAsTable('pnt_bps_int.data_cerdas_ue_monthly_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f4c753a-55ef-45d7-be08-37e6f8b34d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>month=2023-M12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>month=2024-M01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>month=2024-M02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>month=2024-M03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>month=2024-M04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>month=2024-M05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>month=2024-M06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>month=2024-M07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>month=2024-M08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>month=2024-M09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>month=2024-M10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>month=2024-M11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         partition\n",
       "0   month=2023-M12\n",
       "1   month=2024-M01\n",
       "2   month=2024-M02\n",
       "3   month=2024-M03\n",
       "4   month=2024-M04\n",
       "5   month=2024-M05\n",
       "6   month=2024-M06\n",
       "7   month=2024-M07\n",
       "8   month=2024-M08\n",
       "9   month=2024-M09\n",
       "10  month=2024-M10\n",
       "11  month=2024-M11"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"SHOW PARTITIONS pnt_bps_int.data_cerdas_ue_monthly_sample\"\"\"\n",
    "spark.sql(q).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afe1aed1-1a09-4e89-963c-99f63560abee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msisdn</th>\n",
       "      <th>home_h3_8</th>\n",
       "      <th>home_kec</th>\n",
       "      <th>home_entropy</th>\n",
       "      <th>work_h3_8</th>\n",
       "      <th>work_kec</th>\n",
       "      <th>work_entropy</th>\n",
       "      <th>home_kab</th>\n",
       "      <th>work_kab</th>\n",
       "      <th>date</th>\n",
       "      <th>date_6m_ago</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2371386359976944937</td>\n",
       "      <td>888da230c5fffff</td>\n",
       "      <td>35|09|050</td>\n",
       "      <td>1.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35|09</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2024-M01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1274965686682802740</td>\n",
       "      <td>8895059313fffff</td>\n",
       "      <td>73|14|030</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8895059313fffff</td>\n",
       "      <td>73|14|030</td>\n",
       "      <td>1.50</td>\n",
       "      <td>73|14</td>\n",
       "      <td>73|14</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2024-M01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1578913676184715203</td>\n",
       "      <td>8868c8cc89fffff</td>\n",
       "      <td>71|05|120</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8868c8cc89fffff</td>\n",
       "      <td>71|05|120</td>\n",
       "      <td>2.31</td>\n",
       "      <td>71|05</td>\n",
       "      <td>71|05</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2024-M01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7567723583503207360</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>888cf64e4bfffff</td>\n",
       "      <td>16|12|040</td>\n",
       "      <td>2.31</td>\n",
       "      <td>None</td>\n",
       "      <td>16|12</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2024-M01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3164909028423898742</td>\n",
       "      <td>8865246901fffff</td>\n",
       "      <td>21|71|061</td>\n",
       "      <td>3.24</td>\n",
       "      <td>886526a6c3fffff</td>\n",
       "      <td>21|71|061</td>\n",
       "      <td>2.98</td>\n",
       "      <td>21|71</td>\n",
       "      <td>21|71</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2024-M01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1136923908067489651</td>\n",
       "      <td>889500116bfffff</td>\n",
       "      <td>73|05|031</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8895001a57fffff</td>\n",
       "      <td>73|05|031</td>\n",
       "      <td>0.00</td>\n",
       "      <td>73|05</td>\n",
       "      <td>73|05</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2024-M01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-6184012444850013421</td>\n",
       "      <td>888d848d59fffff</td>\n",
       "      <td>35|13|070</td>\n",
       "      <td>3.28</td>\n",
       "      <td>888d848d59fffff</td>\n",
       "      <td>35|13|070</td>\n",
       "      <td>3.14</td>\n",
       "      <td>35|13</td>\n",
       "      <td>35|13</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2024-M01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-7476753881106820274</td>\n",
       "      <td>88652eb201fffff</td>\n",
       "      <td>14|08|010</td>\n",
       "      <td>2.11</td>\n",
       "      <td>88652eb201fffff</td>\n",
       "      <td>14|08|010</td>\n",
       "      <td>1.58</td>\n",
       "      <td>14|08</td>\n",
       "      <td>14|08</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2024-M01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-4695904401745350961</td>\n",
       "      <td>888c160ec3fffff</td>\n",
       "      <td>32|13|190</td>\n",
       "      <td>3.26</td>\n",
       "      <td>888c160ec3fffff</td>\n",
       "      <td>32|13|190</td>\n",
       "      <td>3.14</td>\n",
       "      <td>32|13</td>\n",
       "      <td>32|13</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2024-M01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>531993138834456383</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>886890aa2dfffff</td>\n",
       "      <td>62|09|060</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>62|09</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2024-M01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 msisdn        home_h3_8   home_kec  home_entropy  \\\n",
       "0   2371386359976944937  888da230c5fffff  35|09|050          1.00   \n",
       "1  -1274965686682802740  8895059313fffff  73|14|030          0.00   \n",
       "2  -1578913676184715203  8868c8cc89fffff  71|05|120          0.00   \n",
       "3  -7567723583503207360             None       None           NaN   \n",
       "4  -3164909028423898742  8865246901fffff  21|71|061          3.24   \n",
       "5   1136923908067489651  889500116bfffff  73|05|031          0.00   \n",
       "6  -6184012444850013421  888d848d59fffff  35|13|070          3.28   \n",
       "7  -7476753881106820274  88652eb201fffff  14|08|010          2.11   \n",
       "8  -4695904401745350961  888c160ec3fffff  32|13|190          3.26   \n",
       "9    531993138834456383             None       None           NaN   \n",
       "\n",
       "         work_h3_8   work_kec  work_entropy home_kab work_kab        date  \\\n",
       "0             None       None           NaN    35|09     None  2024-01-31   \n",
       "1  8895059313fffff  73|14|030          1.50    73|14    73|14  2024-01-31   \n",
       "2  8868c8cc89fffff  71|05|120          2.31    71|05    71|05  2024-01-31   \n",
       "3  888cf64e4bfffff  16|12|040          2.31     None    16|12  2024-01-31   \n",
       "4  886526a6c3fffff  21|71|061          2.98    21|71    21|71  2024-01-31   \n",
       "5  8895001a57fffff  73|05|031          0.00    73|05    73|05  2024-01-31   \n",
       "6  888d848d59fffff  35|13|070          3.14    35|13    35|13  2024-01-31   \n",
       "7  88652eb201fffff  14|08|010          1.58    14|08    14|08  2024-01-31   \n",
       "8  888c160ec3fffff  32|13|190          3.14    32|13    32|13  2024-01-31   \n",
       "9  886890aa2dfffff  62|09|060          0.00     None    62|09  2024-01-31   \n",
       "\n",
       "  date_6m_ago     month  \n",
       "0  2023-08-01  2024-M01  \n",
       "1  2023-08-01  2024-M01  \n",
       "2  2023-08-01  2024-M01  \n",
       "3  2023-08-01  2024-M01  \n",
       "4  2023-08-01  2024-M01  \n",
       "5  2023-08-01  2024-M01  \n",
       "6  2023-08-01  2024-M01  \n",
       "7  2023-08-01  2024-M01  \n",
       "8  2023-08-01  2024-M01  \n",
       "9  2023-08-01  2024-M01  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.table('pnt_bps_int.data_cerdas_ue_monthly_sample').limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06f3c22-bb86-4c5c-ba83-a2c471b6ce1f",
   "metadata": {},
   "source": [
    "# UE Semesterly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b533813b-2422-438d-a626-46d04ffd55db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ue_semesterly(ue_monthly,start_date,end_date):\n",
    "    part_home = Window.partitionBy('msisdn').orderBy([col('home_N_month').desc(), col('home_entropy').asc(), col('latest_month').desc()])\n",
    "    part_work = Window.partitionBy('msisdn').orderBy([col('work_N_month').desc(), col('work_entropy').asc(), col('latest_month').desc()])\n",
    "    \n",
    "    period_month = end_date[:7]\n",
    "    # Set 6 months period\n",
    "    ue_semesterly =   ue_monthly\\\n",
    "                        .filter(col('date').between(start_date,end_date))\n",
    "\n",
    "    home_semesterly = ue_semesterly\\\n",
    "                      .groupBy('msisdn','home_h3_8','home_kab','home_kec')\\\n",
    "                      .agg(\n",
    "                          f.countDistinct('month').alias('home_N_month'),\n",
    "                          f.sum('home_entropy').alias('home_entropy'),\n",
    "                          f.max('month').alias('latest_month')\n",
    "                      )\\\n",
    "                      .withColumn('rn', f.row_number().over(part_home))\\\n",
    "                      .filter(col('rn') == 1)\\\n",
    "                      .withColumn('event_month', f.lit(period_month[:4]+'-M'+period_month[-2:]))\\\n",
    "                      .drop('rn','latest_month')\n",
    "\n",
    "    work_semesterly = ue_semesterly\\\n",
    "                      .groupBy('msisdn','work_h3_8','work_kab','work_kec')\\\n",
    "                      .agg(\n",
    "                          f.countDistinct('month').alias('work_N_month'),\n",
    "                          f.sum('work_entropy').alias('work_entropy'),\n",
    "                          f.max('month').alias('latest_month')\n",
    "                      )\\\n",
    "                      .withColumn('rn', f.row_number().over(part_work))\\\n",
    "                      .filter(col('rn') == 1)\\\n",
    "                      .withColumn('event_month', f.lit(period_month[:4]+'-M'+period_month[-2:]))\\\n",
    "                      .drop('rn','latest_month')\n",
    "    \n",
    "    ue_6 = home_semesterly\\\n",
    "        .join(work_semesterly, [ 'msisdn', 'event_month' ], 'full')\\\n",
    "        .select(\n",
    "            'event_month', 'msisdn',\n",
    "            f.coalesce(col('home_h3_8'), col('work_h3_8')).alias('home_h3_8'),\n",
    "            f.coalesce(col('work_h3_8'), col('home_h3_8')).alias('work_h3_8'),\n",
    "            f.coalesce(col('home_kab'), col('work_kab')).alias('home_kab'),\n",
    "            f.coalesce(col('home_kec'), col('work_kec')).alias('home_kec'),\n",
    "            f.coalesce(col('work_kab'), col('home_kab')).alias('work_kab'),\n",
    "            f.coalesce(col('work_kec'), col('home_kec')).alias('work_kec')\n",
    "        )\n",
    "    \n",
    "    return ue_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c78cb73-3c66-46d0-b9f1-2b240259e3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ue_monthly = spark.read.table('pnt_bps_int.data_cerdas_ue_monthly_sample')\n",
    "start_date = '2024-06-01'# perbedaan 6 bulan ke belakang\n",
    "end_date = '2024-11-30' # 6, 7, 8, 9, 10, 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "568f8907-b7f5-48a6-bf2a-27de2ef7e0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_month: string (nullable = true)\n",
      " |-- msisdn: string (nullable = true)\n",
      " |-- home_h3_8: string (nullable = true)\n",
      " |-- work_h3_8: string (nullable = true)\n",
      " |-- home_kab: string (nullable = true)\n",
      " |-- home_kec: string (nullable = true)\n",
      " |-- work_kab: string (nullable = true)\n",
      " |-- work_kec: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ue_semesterly = process_ue_semesterly(ue_monthly,start_date,end_date)\n",
    "ue_semesterly.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53997ee-5621-44e7-a278-74b8ff9b3666",
   "metadata": {},
   "source": [
    "## Looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10388465-7381-4d45-a310-21f3e7252ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configure the logging to save to a file\n",
    "logging.basicConfig(\n",
    "    filename='logging_ue_semesterly_sample.log',  # Name of the log file\n",
    "    level=logging.INFO,  # Set the logging level to INFO\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # Define the format of log messages\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'  # Date format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c72c1e84-31c7-456b-8f43-61ae207c0ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1692795-df8b-4ce7-bbec-0c86515b34cc",
   "metadata": {},
   "source": [
    "## Atur Bulan Di sini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cbffe3b-47c3-4c61-a80d-c01ec9c7614f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "list_month = pd.date_range('2024-05','2024-11',freq='MS')\n",
    "for month in list_month:\n",
    "    \n",
    "    logging.info(f'PROCESS: {month.strftime(\"%Y-%m\")}')\n",
    "    \n",
    "    start_datetime = month - relativedelta(months=5)\n",
    "    end_datetime = month + relativedelta(days=month.days_in_month) - relativedelta(days=1)\n",
    "    start_date = start_datetime.strftime('%Y-%m-%d')\n",
    "    end_date = end_datetime.strftime('%Y-%m-%d')\n",
    "\n",
    "    logging.info(f'START DATE: {start_date}')\n",
    "    logging.info(f'END DATE: {end_date}')\n",
    "    \n",
    "    ue_semesterly = process_ue_semesterly(ue_monthly,start_date,end_date)\n",
    "    \n",
    "    ue_semesterly.repartition(100).write.partitionBy('event_month').mode('append').saveAsTable('pnt_bps_int.data_cerdas_ue_sample')\n",
    "    \n",
    "    logging.info(f'======== DONE ========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a673d-8009-4e67-bd31-80f89f773564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e96365d-5462-4a93-81fa-e267d5e6b671",
   "metadata": {},
   "source": [
    "# Checking UE Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b89bc60-16bd-42d8-a12a-d16b3a39330f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/25 01:39:45 WARN  conf.HiveConf: [Thread-3]: HiveConf of name hive.metastore.runworker.in does not exist\n",
      "25/03/25 01:39:45 WARN  conf.HiveConf: [Thread-3]: HiveConf of name hive.masking.algo does not exist\n"
     ]
    }
   ],
   "source": [
    "ue_monthly = spark.read.table('pnt_bps_int.data_cerdas_ue_monthly_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2448fb20-f47d-470e-b3ea-19b583222fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 317:>                                                        (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.6 ms, sys: 4.25 ms, total: 15.8 ms\n",
      "Wall time: 13.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msisdn</th>\n",
       "      <th>home_h3_8</th>\n",
       "      <th>home_kec</th>\n",
       "      <th>home_entropy</th>\n",
       "      <th>work_h3_8</th>\n",
       "      <th>work_kec</th>\n",
       "      <th>work_entropy</th>\n",
       "      <th>home_kab</th>\n",
       "      <th>work_kab</th>\n",
       "      <th>date</th>\n",
       "      <th>date_6m_ago</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2371386359976944937</td>\n",
       "      <td>888da230c5fffff</td>\n",
       "      <td>35|09|050</td>\n",
       "      <td>1.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35|09</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2024-M01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1274965686682802740</td>\n",
       "      <td>8895059313fffff</td>\n",
       "      <td>73|14|030</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8895059313fffff</td>\n",
       "      <td>73|14|030</td>\n",
       "      <td>1.50</td>\n",
       "      <td>73|14</td>\n",
       "      <td>73|14</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2024-M01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1578913676184715203</td>\n",
       "      <td>8868c8cc89fffff</td>\n",
       "      <td>71|05|120</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8868c8cc89fffff</td>\n",
       "      <td>71|05|120</td>\n",
       "      <td>2.31</td>\n",
       "      <td>71|05</td>\n",
       "      <td>71|05</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2024-M01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7567723583503207360</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>888cf64e4bfffff</td>\n",
       "      <td>16|12|040</td>\n",
       "      <td>2.31</td>\n",
       "      <td>None</td>\n",
       "      <td>16|12</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2024-M01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3164909028423898742</td>\n",
       "      <td>8865246901fffff</td>\n",
       "      <td>21|71|061</td>\n",
       "      <td>3.24</td>\n",
       "      <td>886526a6c3fffff</td>\n",
       "      <td>21|71|061</td>\n",
       "      <td>2.98</td>\n",
       "      <td>21|71</td>\n",
       "      <td>21|71</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2024-M01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1136923908067489651</td>\n",
       "      <td>889500116bfffff</td>\n",
       "      <td>73|05|031</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8895001a57fffff</td>\n",
       "      <td>73|05|031</td>\n",
       "      <td>0.00</td>\n",
       "      <td>73|05</td>\n",
       "      <td>73|05</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2024-M01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-6184012444850013421</td>\n",
       "      <td>888d848d59fffff</td>\n",
       "      <td>35|13|070</td>\n",
       "      <td>3.28</td>\n",
       "      <td>888d848d59fffff</td>\n",
       "      <td>35|13|070</td>\n",
       "      <td>3.14</td>\n",
       "      <td>35|13</td>\n",
       "      <td>35|13</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2024-M01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-7476753881106820274</td>\n",
       "      <td>88652eb201fffff</td>\n",
       "      <td>14|08|010</td>\n",
       "      <td>2.11</td>\n",
       "      <td>88652eb201fffff</td>\n",
       "      <td>14|08|010</td>\n",
       "      <td>1.58</td>\n",
       "      <td>14|08</td>\n",
       "      <td>14|08</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2024-M01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-4695904401745350961</td>\n",
       "      <td>888c160ec3fffff</td>\n",
       "      <td>32|13|190</td>\n",
       "      <td>3.26</td>\n",
       "      <td>888c160ec3fffff</td>\n",
       "      <td>32|13|190</td>\n",
       "      <td>3.14</td>\n",
       "      <td>32|13</td>\n",
       "      <td>32|13</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2024-M01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>531993138834456383</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>886890aa2dfffff</td>\n",
       "      <td>62|09|060</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>62|09</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2024-M01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 msisdn        home_h3_8   home_kec  home_entropy  \\\n",
       "0   2371386359976944937  888da230c5fffff  35|09|050          1.00   \n",
       "1  -1274965686682802740  8895059313fffff  73|14|030          0.00   \n",
       "2  -1578913676184715203  8868c8cc89fffff  71|05|120          0.00   \n",
       "3  -7567723583503207360             None       None           NaN   \n",
       "4  -3164909028423898742  8865246901fffff  21|71|061          3.24   \n",
       "5   1136923908067489651  889500116bfffff  73|05|031          0.00   \n",
       "6  -6184012444850013421  888d848d59fffff  35|13|070          3.28   \n",
       "7  -7476753881106820274  88652eb201fffff  14|08|010          2.11   \n",
       "8  -4695904401745350961  888c160ec3fffff  32|13|190          3.26   \n",
       "9    531993138834456383             None       None           NaN   \n",
       "\n",
       "         work_h3_8   work_kec  work_entropy home_kab work_kab        date  \\\n",
       "0             None       None           NaN    35|09     None  2024-01-31   \n",
       "1  8895059313fffff  73|14|030          1.50    73|14    73|14  2024-01-31   \n",
       "2  8868c8cc89fffff  71|05|120          2.31    71|05    71|05  2024-01-31   \n",
       "3  888cf64e4bfffff  16|12|040          2.31     None    16|12  2024-01-31   \n",
       "4  886526a6c3fffff  21|71|061          2.98    21|71    21|71  2024-01-31   \n",
       "5  8895001a57fffff  73|05|031          0.00    73|05    73|05  2024-01-31   \n",
       "6  888d848d59fffff  35|13|070          3.14    35|13    35|13  2024-01-31   \n",
       "7  88652eb201fffff  14|08|010          1.58    14|08    14|08  2024-01-31   \n",
       "8  888c160ec3fffff  32|13|190          3.14    32|13    32|13  2024-01-31   \n",
       "9  886890aa2dfffff  62|09|060          0.00     None    62|09  2024-01-31   \n",
       "\n",
       "  date_6m_ago     month  \n",
       "0  2023-08-01  2024-M01  \n",
       "1  2023-08-01  2024-M01  \n",
       "2  2023-08-01  2024-M01  \n",
       "3  2023-08-01  2024-M01  \n",
       "4  2023-08-01  2024-M01  \n",
       "5  2023-08-01  2024-M01  \n",
       "6  2023-08-01  2024-M01  \n",
       "7  2023-08-01  2024-M01  \n",
       "8  2023-08-01  2024-M01  \n",
       "9  2023-08-01  2024-M01  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ue_monthly.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e501f511-6609-4452-8449-c3384bc8c154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>month=2023-M12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>month=2024-M01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>month=2024-M02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>month=2024-M03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>month=2024-M04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>month=2024-M05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>month=2024-M06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>month=2024-M07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>month=2024-M08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>month=2024-M09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>month=2024-M10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>month=2024-M11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         partition\n",
       "0   month=2023-M12\n",
       "1   month=2024-M01\n",
       "2   month=2024-M02\n",
       "3   month=2024-M03\n",
       "4   month=2024-M04\n",
       "5   month=2024-M05\n",
       "6   month=2024-M06\n",
       "7   month=2024-M07\n",
       "8   month=2024-M08\n",
       "9   month=2024-M09\n",
       "10  month=2024-M10\n",
       "11  month=2024-M11"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"SHOW PARTITIONS pnt_bps_int.data_cerdas_ue_monthly_sample\"\"\"\n",
    "spark.sql(q).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6b6f788-839a-46ef-8c5b-eeb9161cf9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 306:==================================================> (571 + 12) / 583]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.9 ms, sys: 2.8 ms, total: 39.7 ms\n",
      "Wall time: 11.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>num_row</th>\n",
       "      <th>num_msisdn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-M12</td>\n",
       "      <td>4763453</td>\n",
       "      <td>4763453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-M01</td>\n",
       "      <td>4906492</td>\n",
       "      <td>4906492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-M02</td>\n",
       "      <td>4817474</td>\n",
       "      <td>4817474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-M03</td>\n",
       "      <td>4719132</td>\n",
       "      <td>4719132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-M04</td>\n",
       "      <td>4630604</td>\n",
       "      <td>4630604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-M05</td>\n",
       "      <td>4598242</td>\n",
       "      <td>4598242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-M06</td>\n",
       "      <td>4362195</td>\n",
       "      <td>4362195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024-M07</td>\n",
       "      <td>4297405</td>\n",
       "      <td>4297405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-M08</td>\n",
       "      <td>4122516</td>\n",
       "      <td>4122516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-M09</td>\n",
       "      <td>3924637</td>\n",
       "      <td>3924637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2024-M10</td>\n",
       "      <td>3719294</td>\n",
       "      <td>3719294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-M11</td>\n",
       "      <td>3846119</td>\n",
       "      <td>3846119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       month  num_row  num_msisdn\n",
       "3   2023-M12  4763453     4763453\n",
       "1   2024-M01  4906492     4906492\n",
       "9   2024-M02  4817474     4817474\n",
       "5   2024-M03  4719132     4719132\n",
       "4   2024-M04  4630604     4630604\n",
       "7   2024-M05  4598242     4598242\n",
       "8   2024-M06  4362195     4362195\n",
       "10  2024-M07  4297405     4297405\n",
       "6   2024-M08  4122516     4122516\n",
       "0   2024-M09  3924637     3924637\n",
       "11  2024-M10  3719294     3719294\n",
       "2   2024-M11  3846119     3846119"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ue_monthly.groupBy('month').agg(\n",
    "    F.count('msisdn').alias('num_row'),\n",
    "    F.countDistinct('msisdn').alias('num_msisdn')\n",
    ").toPandas().sort_values('month')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09a1a57-51b8-4150-a33a-5de40318ebd2",
   "metadata": {},
   "source": [
    "# Checking UE Semesterly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f721ab9-dbe9-45be-8105-ff2f6152828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ue_semesterly = spark.read.table('pnt_bps_int.data_cerdas_ue_sample')\n",
    "# ue_semesterly = ue_semesterly.filter(F.col('event_month')=='2024-M12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e82e3cf-6d9b-4a96-984f-40dea6260536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.52 ms, sys: 65 s, total: 8.58 ms\n",
      "Wall time: 490 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msisdn</th>\n",
       "      <th>home_h3_8</th>\n",
       "      <th>work_h3_8</th>\n",
       "      <th>home_kab</th>\n",
       "      <th>home_kec</th>\n",
       "      <th>work_kab</th>\n",
       "      <th>work_kec</th>\n",
       "      <th>event_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3575010115860143924</td>\n",
       "      <td>888cf0846bfffff</td>\n",
       "      <td>888cf095b3fffff</td>\n",
       "      <td>17|05</td>\n",
       "      <td>17|05|010</td>\n",
       "      <td>17|05</td>\n",
       "      <td>17|05|010</td>\n",
       "      <td>2024-M05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1132260017814221523</td>\n",
       "      <td>88652cd637fffff</td>\n",
       "      <td>88652c996bfffff</td>\n",
       "      <td>14|71</td>\n",
       "      <td>14|71|010</td>\n",
       "      <td>14|06</td>\n",
       "      <td>14|06|070</td>\n",
       "      <td>2024-M05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4078250205974930428</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-M05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6369446884781901962</td>\n",
       "      <td>888c14cce7fffff</td>\n",
       "      <td>888c14cce7fffff</td>\n",
       "      <td>32|05</td>\n",
       "      <td>32|05|140</td>\n",
       "      <td>32|05</td>\n",
       "      <td>32|05|140</td>\n",
       "      <td>2024-M05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4154820185226518483</td>\n",
       "      <td>8865212cc9fffff</td>\n",
       "      <td>8865212cc9fffff</td>\n",
       "      <td>14|08</td>\n",
       "      <td>14|08|013</td>\n",
       "      <td>14|08</td>\n",
       "      <td>14|08|013</td>\n",
       "      <td>2024-M05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>862667039292241160</td>\n",
       "      <td>888c106a05fffff</td>\n",
       "      <td>888c106a05fffff</td>\n",
       "      <td>31|74</td>\n",
       "      <td>31|74|040</td>\n",
       "      <td>31|74</td>\n",
       "      <td>31|74|040</td>\n",
       "      <td>2024-M05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3807043185012931184</td>\n",
       "      <td>8895216699fffff</td>\n",
       "      <td>8895216699fffff</td>\n",
       "      <td>73|26</td>\n",
       "      <td>73|26|130</td>\n",
       "      <td>73|26</td>\n",
       "      <td>73|26|130</td>\n",
       "      <td>2024-M05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3766577526323865386</td>\n",
       "      <td>88688e0f5dfffff</td>\n",
       "      <td>88688e0f5dfffff</td>\n",
       "      <td>64|03</td>\n",
       "      <td>64|03|080</td>\n",
       "      <td>64|03</td>\n",
       "      <td>64|03|080</td>\n",
       "      <td>2024-M05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-8530845161508761695</td>\n",
       "      <td>888d8d6ecdfffff</td>\n",
       "      <td>888d899b41fffff</td>\n",
       "      <td>33|02</td>\n",
       "      <td>33|02|170</td>\n",
       "      <td>33|02</td>\n",
       "      <td>33|02|140</td>\n",
       "      <td>2024-M05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-8536780261890682715</td>\n",
       "      <td>88652bc2a1fffff</td>\n",
       "      <td>88652bc223fffff</td>\n",
       "      <td>12|23</td>\n",
       "      <td>12|23|010</td>\n",
       "      <td>12|23</td>\n",
       "      <td>12|23|020</td>\n",
       "      <td>2024-M05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4444854598069067408</td>\n",
       "      <td>888cd629dbfffff</td>\n",
       "      <td>888cd629dbfffff</td>\n",
       "      <td>14|02</td>\n",
       "      <td>14|02|021</td>\n",
       "      <td>14|02</td>\n",
       "      <td>14|02|021</td>\n",
       "      <td>2024-M05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-7470662663738057493</td>\n",
       "      <td>888c145743fffff</td>\n",
       "      <td>888c145743fffff</td>\n",
       "      <td>32|05</td>\n",
       "      <td>32|05|181</td>\n",
       "      <td>32|05</td>\n",
       "      <td>32|05|181</td>\n",
       "      <td>2024-M05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  msisdn        home_h3_8        work_h3_8 home_kab  \\\n",
       "0    3575010115860143924  888cf0846bfffff  888cf095b3fffff    17|05   \n",
       "1   -1132260017814221523  88652cd637fffff  88652c996bfffff    14|71   \n",
       "2   -4078250205974930428             None             None     None   \n",
       "3    6369446884781901962  888c14cce7fffff  888c14cce7fffff    32|05   \n",
       "4    4154820185226518483  8865212cc9fffff  8865212cc9fffff    14|08   \n",
       "5     862667039292241160  888c106a05fffff  888c106a05fffff    31|74   \n",
       "6    3807043185012931184  8895216699fffff  8895216699fffff    73|26   \n",
       "7    3766577526323865386  88688e0f5dfffff  88688e0f5dfffff    64|03   \n",
       "8   -8530845161508761695  888d8d6ecdfffff  888d899b41fffff    33|02   \n",
       "9   -8536780261890682715  88652bc2a1fffff  88652bc223fffff    12|23   \n",
       "10   4444854598069067408  888cd629dbfffff  888cd629dbfffff    14|02   \n",
       "11  -7470662663738057493  888c145743fffff  888c145743fffff    32|05   \n",
       "\n",
       "     home_kec work_kab   work_kec event_month  \n",
       "0   17|05|010    17|05  17|05|010    2024-M05  \n",
       "1   14|71|010    14|06  14|06|070    2024-M05  \n",
       "2        None     None       None    2024-M05  \n",
       "3   32|05|140    32|05  32|05|140    2024-M05  \n",
       "4   14|08|013    14|08  14|08|013    2024-M05  \n",
       "5   31|74|040    31|74  31|74|040    2024-M05  \n",
       "6   73|26|130    73|26  73|26|130    2024-M05  \n",
       "7   64|03|080    64|03  64|03|080    2024-M05  \n",
       "8   33|02|170    33|02  33|02|140    2024-M05  \n",
       "9   12|23|010    12|23  12|23|020    2024-M05  \n",
       "10  14|02|021    14|02  14|02|021    2024-M05  \n",
       "11  32|05|181    32|05  32|05|181    2024-M05  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ue_semesterly.limit(12).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476cba59-fabc-4abf-88e2-e70ab9ee18d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5022a194-29f8-4df3-9baa-5a9815a2c36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 313:===================================================>(573 + 10) / 583]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.6 ms, sys: 1.31 ms, total: 20.9 ms\n",
      "Wall time: 5.97 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_month</th>\n",
       "      <th>num_row</th>\n",
       "      <th>num_msisdn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-M05</td>\n",
       "      <td>5771522</td>\n",
       "      <td>5771522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-M06</td>\n",
       "      <td>5685795</td>\n",
       "      <td>5685795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-M07</td>\n",
       "      <td>5492443</td>\n",
       "      <td>5492443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-M08</td>\n",
       "      <td>5364754</td>\n",
       "      <td>5364754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-M09</td>\n",
       "      <td>5227037</td>\n",
       "      <td>5227037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-M10</td>\n",
       "      <td>5080438</td>\n",
       "      <td>5080438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-M11</td>\n",
       "      <td>4945083</td>\n",
       "      <td>4945083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  event_month  num_row  num_msisdn\n",
       "3    2024-M05  5771522     5771522\n",
       "4    2024-M06  5685795     5685795\n",
       "5    2024-M07  5492443     5492443\n",
       "2    2024-M08  5364754     5364754\n",
       "0    2024-M09  5227037     5227037\n",
       "6    2024-M10  5080438     5080438\n",
       "1    2024-M11  4945083     4945083"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ue_semesterly.groupBy('event_month').agg(\n",
    "    F.count('msisdn').alias('num_row'),\n",
    "    F.countDistinct('msisdn').alias('num_msisdn')\n",
    ").toPandas().sort_values('event_month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d46353-886c-476e-9757-aca6a2c738d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe10f92e-8e3c-4664-b560-3041cdca7ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mobility310)",
   "language": "python",
   "name": "mobility310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
