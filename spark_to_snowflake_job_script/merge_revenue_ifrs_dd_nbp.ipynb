{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "2e6kru6devqzrl2lp7nc",
   "authorId": "644358014528",
   "authorName": "DELOITTE2",
   "authorEmail": "",
   "sessionId": "aeb664bb-b94b-4b5a-aae2-8247ecb73c8f",
   "lastEditTime": 1752480315209
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "source": "import snowflake.snowpark as snowpark\nfrom snowflake.snowpark import Session\nfrom snowflake.snowpark.functions import *\nfrom snowflake.snowpark.types import *\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\n# # Set warehouse if needed\n# session.sql(\"USE WAREHOUSE YOUR_WAREHOUSE_NAME\").collect()\n# session.sql(\"USE DATABASE YOUR_DATABASE_NAME\").collect() \n# session.sql(\"USE SCHEMA YOUR_SCHEMA_NAME\").collect()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "source": "def get_last_partition(session, table_name):\n    \"\"\"\n    Get the last partition from a table in Snowflake\n    Note: Snowflake doesn't use Hive-style partitions, so this might need adjustment\n    based on your table structure\n    \"\"\"\n    try:\n        # If your table has a partition column, adjust this query accordingly\n        result = session.sql(f\"\"\"\n            SELECT MAX(partition_column) as last_partition \n            FROM {table_name}\n        \"\"\").collect()\n        \n        if result:\n            return result[0]['LAST_PARTITION']\n        else:\n            return None\n    except Exception as e:\n        print(f\"Error getting last partition: {e}\")\n        return None\n\ndef process_data(session, env):\n    \"\"\"\n    Process data in Snowflake equivalent to the original PySpark job\n    Based on merge_revenue_ifrs_dd_nbp configuration\n    \"\"\"\n    \n    # Define tables - Snowflake uses database.schema.table format\n    table_1 = f'{env[\"table_1\"][\"database\"]}.{env[\"table_1\"][\"schema\"]}.{env[\"table_1\"][\"table\"]}'\n    table_2 = f'{env[\"table_2\"][\"database\"]}.{env[\"table_2\"][\"schema\"]}.{env[\"table_2\"][\"table\"]}'\n    table_3 = f'{env[\"table_3\"][\"database\"]}.{env[\"table_3\"][\"schema\"]}.{env[\"table_3\"][\"table\"]}'\n    \n    # Define periode (matching the catalog filter patterns)\n    event_date = env[\"table_1\"][\"filter_d2\"]  # day=2 (2 days ago)\n    load_date = env[\"table_1\"][\"filter_d0\"]   # day=0 (today)\n    \n    print(f\"Running for event_date={event_date} and load_date={load_date}\")\n    \n    # Snowflake SQL query - converted from the original PySpark SQL\n    sql_query = f\"\"\"\n    SELECT \n        trx_date,\n        trx_date AS purchase_date,\n        '' AS transaction_id,\n        subs_id,\n        a.msisdn,\n        offer_id::INTEGER AS price_plan_id,\n        brand,\n        pre_post_flag::INTEGER AS pre_post_flag,\n        cust_type_desc,\n        cust_subtype_desc,\n        '' AS customer_sub_segment,\n        lac,\n        ci,\n        lacci_id,\n        node_type AS node,\n        CASE \n            WHEN area_sales IS NULL OR area_sales = '' THEN 'UNKNOWN' \n            ELSE area_sales \n        END AS area_sales,\n        CASE \n            WHEN region_sales IS NULL OR region_sales = '' THEN 'UNKNOWN' \n            ELSE region_sales \n        END AS region_sales,\n        CASE \n            WHEN branch IS NULL OR branch = '' THEN 'UNKNOWN' \n            ELSE branch \n        END AS branch,\n        CASE \n            WHEN subbranch IS NULL OR subbranch = '' THEN 'UNKNOWN' \n            ELSE subbranch \n        END AS subbranch,\n        CASE \n            WHEN cluster_sales IS NULL OR cluster_sales = '' THEN 'UNKNOWN' \n            ELSE cluster_sales \n        END AS cluster_sales,\n        CASE \n            WHEN provinsi IS NULL OR provinsi = '' THEN 'UNKNOWN' \n            ELSE provinsi \n        END AS provinsi,\n        CASE \n            WHEN kabupaten IS NULL OR kabupaten = '' THEN 'UNKNOWN' \n            ELSE kabupaten \n        END AS kabupaten,\n        CASE \n            WHEN kecamatan IS NULL OR kecamatan = '' THEN 'UNKNOWN' \n            ELSE kecamatan \n        END AS kecamatan,\n        CASE \n            WHEN kelurahan IS NULL OR kelurahan = '' THEN 'UNKNOWN' \n            ELSE kelurahan \n        END AS kelurahan,\n        lacci_closing_flag::INTEGER AS lacci_closing_flag,\n        SUBSTR(content_id, 1, 8) AS sigma_business_id,\n        SUBSTR(pack_id, 9, 5) AS sigma_rules_id,\n        '' AS sku,\n        '' AS l1_payu,\n        '' AS l2_service_type,\n        '' AS l3_allowance_type,\n        '' AS l4_product_category,\n        '' AS l5_product,\n        l1_name AS l1_ias,\n        l2_name AS l2_ias,\n        l3_name AS l3_ias,\n        '' AS commercial_name,\n        '' AS channel,\n        '' AS pack_validity,\n        SUM(rev/1.11)::DECIMAL(38,15) AS rev_per_usage,\n        SUM(0)::DECIMAL(38,15) AS rev_seized,\n        SUM(dur)::INTEGER AS dur,\n        SUM(trx)::INTEGER AS trx,\n        SUM(vol)::BIGINT AS vol,\n        NULL AS cust_id,\n        '' AS profile_name,\n        '' AS quota_name,\n        '' AS service_filter,\n        offer AS price_plan_name,\n        activation_channel_id AS channel_id,\n        '' AS site_id,\n        '' AS site_name,\n        region_hlr,\n        city_hlr,\n        '{load_date}' AS load_date,\n        a.event_date,\n        'WISDOM-NBP' AS SOURCE\n\n    FROM (\n        SELECT a.* \n        FROM (\n            SELECT a.* \n            FROM (\n                SELECT *\n                FROM {table_1}\n                WHERE event_date = '{event_date}'\n                  AND pre_post_flag = '1'\n                  AND l1_name = 'Digital Services'\n                  AND LOWER(l3_name) NOT LIKE 'phonebook%backup'\n                  AND SOURCE IN ('CHG_GOOD','CHG_REJECT')\n            ) a\n\n            INNER JOIN (\n                SELECT \n                    event_date,\n                    LPAD(business_id, 8, '0') AS bid\n                FROM {table_2}\n                WHERE event_date = '{event_date}'\n                  AND status_flag = 'Y'\n                  AND LOWER(ifrs_flag) = 'true'\n                GROUP BY 1,2\n            ) c9\n            ON a.event_date = c9.event_date\n              AND SUBSTR(pack_id, 1, 8) = c9.bid\n        ) a\n\n        LEFT JOIN (\n            SELECT sigma_business_id\n            FROM {table_3}\n            WHERE event_date = '{event_date}'\n              AND SOURCE IN ('CHG','SEIZED','UPCC-SEIZED','UPCC_USAGE','PAYU','WISDOM')\n            GROUP BY 1\n        ) b\n        ON SUBSTR(pack_id, 1, 8) = b.sigma_business_id\n        WHERE b.sigma_business_id IS NULL\n    ) a\n\n    GROUP BY 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,45,46,47,48,49,50,51,52,53,54,55,56,57\n    \"\"\"\n    \n    # Execute the query\n    df = session.sql(sql_query)\n    \n    return df",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c0de5e9e-7bd8-4ffd-98a7-1afae698f125",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "try:\n    env = {\n        \"table_1\": {\n            \"database\": \"TELKOMSEL_POC\",                        # From catalog\n            \"schema\": \"RAW\",                           # Update with your schema\n            \"table\": \"MERGE_REVENUE_DD_POC_TOKENIZED\",    # From catalog\n            \"filter_d2\": \"2025-04-01\",                   # Hardcoded: event_date (2 days ago)\n            \"filter_d0\": \"2025-04-01\"                    # Hardcoded: load_date (today)\n        },\n        \"table_2\": {\n            \"database\": \"TELKOMSEL_POC\",                        # From catalog\n            \"schema\": \"RAW\",                           # Update with your schema\n            \"table\": \"PRODUCT_CATALOG_IFRS_C2C_DD_POC_TOKENIZED\",  # From catalog\n            \"filter_d2\": \"2025-04-01\",                   # Hardcoded: event_date\n        },\n        \"table_3\": {\n            \"database\": \"TELKOMSEL_POC\",                        # From catalog\n            \"schema\": \"RAW\",                           # Update with your schema\n            \"table\": \"MERGE_REVENUE_IFRS_DD_POC_TOKENIZED\",  # From catalog\n            \"filter_d2\": \"2025-04-01\",                   # Hardcoded: event_date\n        }\n    }\n    \n    # Process the data\n    result_df = process_data(session, env)\n    \n    # Show results\n    print(\"Processing completed successfully!\")\n    result_df.show(10)  # Show first 10 rows\n    \nexcept Exception as e:\n    print(f\"Error processing data: {e}\")\n    raise",
   "execution_count": null
  }
 ]
}