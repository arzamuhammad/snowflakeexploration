{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "import snowflake.snowpark as snowpark\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import *\n",
    "from snowflake.snowpark.types import *\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "# # Set warehouse if needed\n",
    "# session.sql(\"USE WAREHOUSE YOUR_WAREHOUSE_NAME\").collect()\n",
    "# session.sql(\"USE DATABASE YOUR_DATABASE_NAME\").collect() \n",
    "# session.sql(\"USE SCHEMA YOUR_SCHEMA_NAME\").collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "def get_last_partition(session, table_name):\n",
    "    \"\"\"\n",
    "    Get the last partition from a table in Snowflake\n",
    "    Note: Snowflake doesn't use Hive-style partitions, so this might need adjustment\n",
    "    based on your table structure\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # If your table has a partition column, adjust this query accordingly\n",
    "        result = session.sql(f\"\"\"\n",
    "            SELECT MAX(partition_column) as last_partition \n",
    "            FROM {table_name}\n",
    "        \"\"\").collect()\n",
    "        \n",
    "        if result:\n",
    "            return result[0]['LAST_PARTITION']\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting last partition: {e}\")\n",
    "        return None\n",
    "def get_last_partition(session, table_name):\n",
    "    \"\"\"\n",
    "    Get the last partition from a table in Snowflake\n",
    "    Note: Snowflake doesn't use Hive-style partitions, so this might need adjustment\n",
    "    based on your table structure\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # If your table has a partition column, adjust this query accordingly\n",
    "        result = session.sql(f\"\"\"\n",
    "            SELECT MAX(partition_column) as last_partition \n",
    "            FROM {table_name}\n",
    "        \"\"\").collect()\n",
    "        \n",
    "        if result:\n",
    "            return result[0]['LAST_PARTITION']\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting last partition: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_data(session, env):\n",
    "    \"\"\"\n",
    "    Process breakage data in Snowflake equivalent to the original PySpark job\n",
    "    Based on merge_revenue_ifrs_dd_breakage configuration\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define tables - Snowflake uses database.schema.table format\n",
    "    table_1 = f'{env[\"table_1\"][\"database\"]}.{env[\"table_1\"][\"schema\"]}.{env[\"table_1\"][\"table\"]}'\n",
    "    table_2 = f'{env[\"table_2\"][\"database\"]}.{env[\"table_2\"][\"schema\"]}.{env[\"table_2\"][\"table\"]}'\n",
    "    table_3 = f'{env[\"table_3\"][\"database\"]}.{env[\"table_3\"][\"schema\"]}.{env[\"table_3\"][\"table\"]}'\n",
    "    table_4 = f'{env[\"table_4\"][\"database\"]}.{env[\"table_4\"][\"schema\"]}.{env[\"table_4\"][\"table\"]}'\n",
    "    \n",
    "    # Define periode (matching the catalog filter patterns)\n",
    "    event_date = env[\"table_1\"][\"filter_d2\"]  # day=2 (2 days ago)\n",
    "    load_date = env[\"table_1\"][\"filter_d0\"]   # day=0 (today)\n",
    "    month_date = env[\"table_2\"][\"filter_month\"]  # month=0 (current month)\n",
    "    \n",
    "    print(f\"Running for event_date={event_date} and load_date={load_date}\")\n",
    "    \n",
    "    # Snowflake SQL query - converted from the original PySpark SQL\n",
    "    sql_query = f\"\"\"\n",
    "    SELECT \n",
    "        trx_date,\n",
    "        trx_date AS purchase_date,\n",
    "        transaction_id,\n",
    "        '' AS subs_id,\n",
    "        a.msisdn,\n",
    "        c1.price_plan_id::INTEGER AS price_plan_id,\n",
    "        brand,\n",
    "        1 AS pre_post_flag,\n",
    "        cust_type_desc,\n",
    "        cust_subtype_desc,\n",
    "        customer_sub_segment,\n",
    "        '' AS lac,\n",
    "        '' AS ci,\n",
    "        lacci_id,\n",
    "        '' AS node,\n",
    "        area_sales,\n",
    "        a.region_sales,\n",
    "        branch,\n",
    "        subbranch,\n",
    "        cluster_sales,\n",
    "        provinsi,\n",
    "        kabupaten,\n",
    "        kecamatan,\n",
    "        kelurahan,\n",
    "        NULL AS lacci_closing_flag,\n",
    "        business_id AS sigma_business_id,\n",
    "        rules_id AS sigma_rules_id,\n",
    "        sku,\n",
    "        '' AS l1_payu,\n",
    "        '' AS l2_service_type,\n",
    "        a.allowance_sub_type AS l3_allowance_type,\n",
    "        '' AS l4_product_category,\n",
    "        '' AS l5_product,\n",
    "        '' AS l1_ias,\n",
    "        '' AS l2_ias,\n",
    "        '' AS l3_ias,\n",
    "        '' AS commercial_name,\n",
    "        '' AS channel,\n",
    "        '' AS pack_validity,\n",
    "        SUM(breakage * allocation_rate)::DECIMAL(38,15) AS rev_per_usage,\n",
    "        SUM(0)::DECIMAL(38,15) AS rev_seized,\n",
    "        SUM(0)::INTEGER AS dur,\n",
    "        SUM(0)::INTEGER AS trx,\n",
    "        SUM(0)::BIGINT AS vol,\n",
    "        NULL AS cust_id,\n",
    "        profile_name,\n",
    "        quota_name,\n",
    "        '' AS service_filter,\n",
    "        '' AS price_plan_name,\n",
    "        '' AS channel_id,\n",
    "        '' AS site_id,\n",
    "        '' AS site_name,\n",
    "        region_hlr,\n",
    "        '' AS city_hlr,\n",
    "        '{load_date}' AS load_date,\n",
    "        a.event_date,\n",
    "        SOURCE\n",
    "    FROM (\n",
    "        SELECT \n",
    "            trx_date,\n",
    "            transaction_id,\n",
    "            msisdn,\n",
    "            brand,\n",
    "            cust_type_desc,\n",
    "            cust_subtype_desc,\n",
    "            customer_sub_segment,\n",
    "            lacci_id,\n",
    "            area_sales,\n",
    "            region_sales,\n",
    "            branch,\n",
    "            subbranch,\n",
    "            cluster_sales,\n",
    "            provinsi,\n",
    "            kabupaten,\n",
    "            kecamatan,\n",
    "            kelurahan,\n",
    "            business_id,\n",
    "            rules_id,\n",
    "            sku,\n",
    "            allowance_sub_type,\n",
    "            allowance,\n",
    "            profile_name,\n",
    "            quota_name,\n",
    "            region_hlr,\n",
    "            event_date,\n",
    "            SUM(breakage) AS breakage,\n",
    "            SUM(rev_seized) AS rev_seized,\n",
    "            SOURCE\n",
    "        FROM (\n",
    "            SELECT \n",
    "                trx_date,\n",
    "                transaction_id,\n",
    "                msisdn,\n",
    "                brand,\n",
    "                cust_type_desc,\n",
    "                cust_subtype_desc,\n",
    "                customer_sub_segment,\n",
    "                lacci_id,\n",
    "                area_sales,\n",
    "                region_sales,\n",
    "                branch,\n",
    "                subbranch,\n",
    "                cluster_sales,\n",
    "                provinsi,\n",
    "                kabupaten,\n",
    "                kecamatan,\n",
    "                kelurahan,\n",
    "                business_id,\n",
    "                rules_id,\n",
    "                sku,\n",
    "                allowance_sub_type,\n",
    "                allowance,\n",
    "                profile_name,\n",
    "                quota_name,\n",
    "                region_hlr,\n",
    "                event_date,\n",
    "                SUM(breakage) AS breakage,\n",
    "                '0' AS rev_seized,\n",
    "                'BREAKAGE' AS SOURCE\n",
    "            FROM {table_1} a\n",
    "            WHERE event_date = '{event_date}'\n",
    "            GROUP BY 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,28\n",
    "            \n",
    "            UNION ALL\n",
    "            \n",
    "            SELECT \n",
    "                trx_date,\n",
    "                transaction_id,\n",
    "                msisdn,\n",
    "                brand,\n",
    "                cust_type_desc,\n",
    "                cust_subtype_desc,\n",
    "                customer_sub_segment,\n",
    "                lacci_id,\n",
    "                area_sales,\n",
    "                region_sales,\n",
    "                branch,\n",
    "                subbranch,\n",
    "                cluster_sales,\n",
    "                provinsi,\n",
    "                kabupaten,\n",
    "                kecamatan,\n",
    "                kelurahan,\n",
    "                sigma_business_id AS business_id,\n",
    "                sigma_rules_id AS rules_id,\n",
    "                sku,\n",
    "                l3_allowance_type AS allowance_sub_type,\n",
    "                CASE \n",
    "                    WHEN UPPER(l3_allowance_type) LIKE '%DATA%'\n",
    "                      OR UPPER(l3_allowance_type) LIKE '%UPCC%' THEN 'DATA'\n",
    "                    WHEN UPPER(l3_allowance_type) LIKE '%SMS%' THEN 'SMS'\n",
    "                    WHEN UPPER(l3_allowance_type) LIKE '%VOICE%' THEN 'VOICE'\n",
    "                    ELSE 'NONUSAGE' \n",
    "                END AS allowance,\n",
    "                profile_name,\n",
    "                quota_name,\n",
    "                region_hlr,\n",
    "                event_date,\n",
    "                SUM(rev_seized * -1) AS breakage,\n",
    "                '0' AS rev_seized,\n",
    "                'BREAKAGE-SEIZED' AS SOURCE\n",
    "            FROM {table_2}\n",
    "            WHERE event_date = '{event_date}'\n",
    "              AND SUBSTR(purchase_date, 1, 7) = '{month_date}'\n",
    "              AND SOURCE IN ('SEIZED','UPCC-SEIZED')\n",
    "              AND pre_post_flag = '1'\n",
    "            GROUP BY 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,28\n",
    "        ) a\n",
    "        GROUP BY 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,29\n",
    "    ) a\n",
    "    \n",
    "    LEFT JOIN (\n",
    "        SELECT \n",
    "            event_date,\n",
    "            msisdn,\n",
    "            offer_id AS price_plan_id\n",
    "        FROM {table_3}\n",
    "        WHERE event_date = '{event_date}'\n",
    "          AND pre_post_flag = '1'\n",
    "        GROUP BY 1,2,3\n",
    "    ) c1\n",
    "    ON a.event_date = c1.event_date\n",
    "       AND a.msisdn = c1.msisdn\n",
    "    \n",
    "    INNER JOIN (\n",
    "        SELECT * \n",
    "        FROM {table_4}\n",
    "        WHERE event_date IN (SELECT MAX(event_date) FROM {table_4})\n",
    "    ) b1\n",
    "    ON a.allowance = b1.allowance_type\n",
    "       AND a.region_sales = b1.region\n",
    "    \n",
    "    GROUP BY 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,45,46,47,48,49,50,51,52,53,54,55,56,57\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query\n",
    "    df = session.sql(sql_query)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0de5e9e-7bd8-4ffd-98a7-1afae698f125",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    env = {\n",
    "        \"table_1\": {\n",
    "            \"database\": \"TELKOMSEL_POC\",\n",
    "            \"schema\": \"public\",\n",
    "            \"table\": \"STG_BREAKAGE_POC_TOKENIZED\",\n",
    "            \"filter_d2\": \"2025-04-01\",     # Hardcoded: 1st April 2025 (event_date)\n",
    "            \"filter_d0\": \"2025-04-01\"      # Hardcoded: 2nd April 2025 (load_date)\n",
    "        },\n",
    "        \"table_2\": {\n",
    "            \"database\": \"TELKOMSEL_POC\",\n",
    "            \"schema\": \"RAW\",\n",
    "            \"table\": \"MERGE_REVENUE_IFRS_DD_POC_TOKENIZED\",\n",
    "            \"filter_d2\": \"2025-04-01\",     # Hardcoded: 1st April 2025 (event_date)\n",
    "            \"filter_month\": \"2025-04\"      # Hardcoded: April 2025 (month filter)\n",
    "        },\n",
    "        \"table_3\": {\n",
    "            \"database\": \"TELKOMSEL_POC\",\n",
    "            \"schema\": \"RAW\",\n",
    "            \"table\": \"MERGE_REVENUE_DD_POC_TOKENIZED\",\n",
    "            \"filter_d2\": \"2025-04-01\",     # Hardcoded: 1st April 2025 (event_date)\n",
    "        },\n",
    "        \"table_4\": {\n",
    "            \"database\": \"TELKOMSEL_POC\",\n",
    "            \"schema\": \"RAW\",\n",
    "            \"table\": \"BREAKAGE_REFERENCE_POC_TOKENIZED\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Process the data\n",
    "    result_df = process_data(session, env)\n",
    "    \n",
    "    # Show results\n",
    "    print(\"Processing completed successfully!\")\n",
    "    result_df.show(10)  # Show first 10 rows\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error processing data: {e}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "",
   "authorId": "644358014528",
   "authorName": "DELOITTE2",
   "lastEditTime": 1752479246996,
   "notebookId": "2e6kru6devqzrl2lp7nc",
   "sessionId": "aeb664bb-b94b-4b5a-aae2-8247ecb73c8f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
